{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop 1 - CHESS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWx4QPIKVCW5",
        "colab_type": "text"
      },
      "source": [
        "# **INTRO TO MACHINE LEARNING - DECISION TREE AND LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDF5HsCTVcZA",
        "colab_type": "text"
      },
      "source": [
        "# To find all the materials for this workshop please see the GitHub repo here: https://github.com/aisutd/Workshop1_Chess_Fall2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZs0TxeTV-3L",
        "colab_type": "text"
      },
      "source": [
        "## CHESS DATASET\n",
        "\n",
        "This is a kaggle dataset which was collected from over 20,000 games on the site Lichess.org. There are several teams on Lichess with over 1,500 players. it has 20058 rows and 16 columns.\n",
        "\n",
        "It has the following attributes :- \n",
        "*   Game ID\n",
        "*   Rated - indicates the genuinity of the game played\n",
        "*   Start time\n",
        "*   End time\n",
        "*   Number of Turns\n",
        "*   Game Status - whether the game was resigned or it resulted in checkmate\n",
        "*   Winner - white / black\n",
        "*   Time Increment\n",
        "*   White Player ID\n",
        "*   White Player Rating\n",
        "*   Black Player ID\n",
        "*   Black Player Rating\n",
        "*   All Moves in Standard Chess Notation\n",
        "*   Opening Eco (Standardised Code for any given opening)\n",
        "*   Opening Name\n",
        "*   Opening Ply (Number of moves in the opening phase)\n",
        "\n",
        "Lots of information is contained within a single chess game, let alone a full dataset of multiple games. It is primarily a game of patterns, and data science is all about detecting patterns in data, which is why chess has been one of the most invested in areas of AI in the past. \n",
        "Though, we can construct many goals for this dataset, in this workshop our main aim is to predict the winner of the game at Early-game, Mid-game and End-game stages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5akp01Qa5HZ",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhb5MqjGa_na",
        "colab_type": "text"
      },
      "source": [
        "Numpy and Pandas help us to manipulate data and makes it easier to use them.\n",
        "Matplotlib and Seaborn helps us visualise data. Io is required to import dataset into Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVnWEEGjbCRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNsc4xDtbdY1",
        "colab_type": "text"
      },
      "source": [
        "**Uploading file from the computer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wka7cmd8bf-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzku5RN-c661",
        "colab_type": "text"
      },
      "source": [
        "**Loading the dataset into a pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpRIXcqEdSqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(io.StringIO(uploaded['games.csv'].decode('utf-8')))\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN3uIiA7eLAY",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing and Visualisation\n",
        "\n",
        "* We will mainly see which columns are required (based on the goal and it's relevance to    the target variable - \"WINNER\"). \n",
        "* We will also remove those columns that are highly correlated to another column. (Correlation measures the strength of the linear relationship between two quantitative variables). So we either discard the other variable as they measure the same thing or we create a new variable that combines the effects of the highly correlated group.\n",
        "* We will also play around with the feature \"Moves\" - try creating new features from it. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDJTCzZ7gV-S",
        "colab_type": "text"
      },
      "source": [
        "**Dropping Columns based on their relevance to goal**\n",
        "\n",
        "We will remove the following columns :-\n",
        "* id (unique value for each row)\n",
        "* rated (irrelevant)\n",
        "* created_at (irrelevant)\n",
        "* last_move_at (irrelevant)\n",
        "* increment_code (irrelevant)\n",
        "* white_id (list of names - irrelevant)\n",
        "* black_id (list of names - irrelevant)\n",
        "* opening_eco\n",
        "* opening_name\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnc4xKNhveB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop unneccessary columns\n",
        "dropped_df = df.drop(\n",
        "    ['id', 'rated', 'created_at', 'last_move_at', 'increment_code', 'white_id',\n",
        "     'black_id', 'opening_eco', 'opening_name','victory_status'],\n",
        "     axis=1\n",
        ")\n",
        "dropped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNT2S_Rie5H",
        "colab_type": "text"
      },
      "source": [
        "This code allows us to drop these columns specified by name. \"Axis=1\" indicates that we are altering the data vertically. \"inplace=True\" indicates that we make these changes to the same dataframe and there's no need to create another copy. \n",
        "\n",
        "Thus, we are now left with a dataset of only 7 columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqIc3DNYvCmM",
        "colab_type": "text"
      },
      "source": [
        "We can place a **threshold on the number of moves (turns) each game** should have. Here, we keep the **threshold = 15**. So for games having turns less than 15 must be filtered out. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkwqJt4CvIQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop unneccessary games\n",
        "\n",
        "index_cond = dropped_df[ dropped_df['turns'] < 15 ].index\n",
        " \n",
        "# Delete these row indexes from dataFrame\n",
        "dropped_df.drop(index_cond , inplace=True)\n",
        "dropped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFg0JGCZnnvv",
        "colab_type": "text"
      },
      "source": [
        "### Working on the moves column\n",
        "\n",
        "The moves column is represented using the algebraic notation.\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/SCD_algebraic_notation.svg/500px-SCD_algebraic_notation.svg.png)\n",
        "\n",
        "* Each square of the chessboard is identified by a unique coordinate pair‚Äîa letter and a number. The vertical columns of squares are labeled a through h from White's left to right. The horizontal rows of squares are numbered 1 to 8 starting from White's side of the board.\n",
        "* Each piece is identified by a letter -  K for king, Q for queen, R for rook, B for bishop, and N for knight. Pawns are not identified by uppercase letters, but rather by the absence of one.\n",
        "* When a piece makes a capture, an \"x\" is inserted immediately before the destination square. For example, Bxe5 (bishop captures the piece on e5). When a pawn makes a capture, the column from which the pawn departed is used to identify the pawn. For example, exd5 (pawn on the e-column captures the piece on d5)\n",
        "* A move that places the opponent's king in check usually has the symbol \"+\" appended. Double check is commonly indicated the same as check.\n",
        "\n",
        "\n",
        "We can extract a lot of information from this feature. \n",
        "* We can first split them into early game, mid game and end game stages. The early game moves can be seperated based on the column 'opening_ply'. The rest of the moves can be split into mid and end stages in ratio 70:30 (randomly selected). Then we can split each row into black and white moves.\n",
        "* Count the number of moves made by each piece in each stage of both sides. \n",
        "* Count the number of checks made by each piece at the end of each stages.\n",
        "* Also count the number of pieces captured by each piece of both sides, stage-wise.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr23g_7v1Bzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to split game into three stages - opening, mid and end for black and \n",
        "# white\n",
        "def splitMovesIntoStages(moves,opening_ply):\n",
        "    count_row = 0\n",
        "    early_black_row = []\n",
        "    early_white_row = []\n",
        "    mid_black_row = []\n",
        "    mid_white_row = []\n",
        "    end_black_row = []\n",
        "    end_white_row = []\n",
        "    \n",
        "    # considering each row of the moves column\n",
        "    element = [move for move in moves.split(' ')]\n",
        "\n",
        "    # accessing the 'opening_ply' column row by row\n",
        "    opening_moves = int(opening_ply)  \n",
        "\n",
        "    rest_length = len(element) - int(opening_moves)\n",
        "    mid_length = math.ceil(rest_length * 0.7)\n",
        "    end_length = rest_length - mid_length\n",
        "    \n",
        "    # considering each element of each row of moves column and split them into \n",
        "    # stages (early, mide and black) and withn each stage into black and white\n",
        "    for k in range(0, len(element)):\n",
        "        # EARLY STAGE\n",
        "        if k < opening_moves:\n",
        "\n",
        "            if k % 2 == 0:  # WHITE OCCUPIES EVEN MOVES\n",
        "                early_white_row.append(element[k])\n",
        "            else:  # BLACK OCCUPIES ODD MOVES\n",
        "                early_black_row.append(element[k])\n",
        "\n",
        "        # MID STAGE\n",
        "        elif k >= opening_moves and k < opening_moves + mid_length:\n",
        "            if k % 2 == 0:\n",
        "                mid_white_row.append(element[k])\n",
        "            else:\n",
        "                mid_black_row.append(element[k])\n",
        "\n",
        "        # END STAGE\n",
        "        else:\n",
        "          if k % 2 == 0:\n",
        "            end_white_row.append(element[k])\n",
        "          else:\n",
        "            end_black_row.append(element[k])\n",
        "    \n",
        "    \n",
        "    return early_white_row, early_black_row, mid_white_row,mid_black_row,end_white_row,end_black_row\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW7PZhOLoRs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split game into opening,mid and end\n",
        "(dropped_df['Early_stage_white_moves'],\n",
        " dropped_df['Early_stage_black_moves'],\n",
        " dropped_df['Mid_stage_white_moves'],\n",
        " dropped_df['Mid_stage_black_moves'],\n",
        " dropped_df['End_stage_white_moves'],\n",
        " dropped_df['End_stage_black_moves']) = zip(*dropped_df.apply(lambda row: splitMovesIntoStages(row['moves'], row['opening_ply']), axis=1))\n",
        "\n",
        "dropped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_KnxHOEYCAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate no of moves for each piece\n",
        "def movesByEachPiece(moves):\n",
        "  \n",
        "  noOfKingMoves = 0\n",
        "  noOfQueenMoves = 0\n",
        "  noOfRookMoves = 0\n",
        "  noOfBishopMoves = 0\n",
        "  noOfKnightMoves = 0\n",
        "  noOfPawnMoves = 0\n",
        "  \n",
        "  for move in moves:\n",
        "    if move.startswith('K'):\n",
        "      noOfKingMoves += 1\n",
        "    elif move.startswith('Q'):\n",
        "      noOfQueenMoves += 1\n",
        "    elif move.startswith('R'):\n",
        "      noOfRookMoves += 1\n",
        "    elif move.startswith('B'):\n",
        "      noOfBishopMoves += 1\n",
        "    elif move.startswith('N'):\n",
        "      noOfKnightMoves += 1\n",
        "    else:\n",
        "      noOfPawnMoves += 1\n",
        "  return (\n",
        "      noOfKingMoves,\n",
        "      noOfQueenMoves,\n",
        "      noOfRookMoves,\n",
        "      noOfBishopMoves,\n",
        "      noOfKnightMoves,\n",
        "      noOfPawnMoves\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akVz44cVodO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate no of moves for all pieces for white early game\n",
        "(dropped_df['king_early_moves_white'],\n",
        "dropped_df['queen_early_moves_white'],\n",
        "dropped_df['rook_early_moves_white'],\n",
        "dropped_df['bishop_early_moves_white'],\n",
        "dropped_df['knight_early_moves_white'],\n",
        "dropped_df['pawn_early_moves_white']) = zip(*dropped_df['Early_stage_white_moves'].apply(movesByEachPiece))\n",
        "\n",
        "#calculate no of moves for all pieces for white mid game\n",
        "(dropped_df['king_mid_moves_white'],\n",
        "dropped_df['queen_mid_moves_white'],\n",
        "dropped_df['rook_mid_moves_white'],\n",
        "dropped_df['bishop_mid_moves_white'],\n",
        "dropped_df['knight_mid_moves_white'],\n",
        "dropped_df['pawn_mid_moves_white']) = zip(*dropped_df['Mid_stage_white_moves'].apply(movesByEachPiece))\n",
        "\n",
        "#calculate no of moves for all pieces for white end game\n",
        "(dropped_df['king_end_moves_white'],\n",
        "dropped_df['queen_end_moves_white'],\n",
        "dropped_df['rook_end_moves_white'], \n",
        "dropped_df['bishop_end_moves_white'],\n",
        "dropped_df['knight_end_moves_white'],\n",
        "dropped_df['pawn_end_moves_white']) = zip(*dropped_df['End_stage_white_moves'].apply(movesByEachPiece))\n",
        "\n",
        "#calculate no of moves for all pieces for black early game\n",
        "(dropped_df['king_early_moves_black'],\n",
        "dropped_df['queen_early_moves_black'],\n",
        "dropped_df['rook_early_moves_black'],\n",
        "dropped_df['bishop_early_moves_black'],\n",
        "dropped_df['knight_early_moves_black'],\n",
        "dropped_df['pawn_early_moves_black']) = zip(*dropped_df['Early_stage_black_moves'].apply(movesByEachPiece))\n",
        "\n",
        "#calculate no of moves for all pieces for black mid game\n",
        "(dropped_df['king_mid_moves_black'],\n",
        "dropped_df['queen_mid_moves_black'],\n",
        "dropped_df['rook_mid_moves_black'],\n",
        "dropped_df['bishop_mid_moves_black'],\n",
        "dropped_df['knight_mid_moves_black'],\n",
        "dropped_df['pawn_mid_moves_black']) = zip(*dropped_df['Mid_stage_black_moves'].apply(movesByEachPiece))\n",
        "\n",
        "#calculate no of moves for all pieces for black mid game\n",
        "(dropped_df['king_end_moves_black'],\n",
        "dropped_df['queen_end_moves_black'],\n",
        "dropped_df['rook_end_moves_black'],\n",
        "dropped_df['bishop_end_moves_black'],\n",
        "dropped_df['knight_end_moves_black'],\n",
        "dropped_df['pawn_end_moves_black']) = zip(*dropped_df['End_stage_black_moves'].apply(movesByEachPiece))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e1O2sn8o7og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOjNXmTWpHY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate number of checks in each phase by black and white\n",
        "def checksByEachSide(moves):\n",
        "  checks = 0\n",
        "  for move in moves:\n",
        "    if '+' in move:\n",
        "      checks += 1;\n",
        "  return checks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMhjczVQpIGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checks by white in each phase\n",
        "dropped_df['checks_early_white'] = dropped_df['Early_stage_white_moves'].apply(checksByEachSide)\n",
        "dropped_df['checks_mid_white'] = dropped_df['Mid_stage_white_moves'].apply(checksByEachSide)\n",
        "dropped_df['checks_end_white'] = dropped_df['End_stage_white_moves'].apply(checksByEachSide)\n",
        "\n",
        "#checks by black in each phase\n",
        "dropped_df['checks_early_black'] = dropped_df['Early_stage_black_moves'].apply(checksByEachSide)\n",
        "dropped_df['checks_mid_black'] = dropped_df['Mid_stage_black_moves'].apply(checksByEachSide)\n",
        "dropped_df['checks_end_black'] = dropped_df['End_stage_black_moves'].apply(checksByEachSide)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5qq3OmIpTNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVTCZm-BpKav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate number of pieces captured by each piece\n",
        "def capturesByEachPiece(moves):\n",
        "  noOfCapturesByKing = 0\n",
        "  noOfCapturesByQueen = 0\n",
        "  noOfCapturesByRook = 0\n",
        "  noOfCapturesByBishop = 0\n",
        "  noOfCapturesByKnight = 0\n",
        "  noOfCapturesByPawn = 0\n",
        "  for move in moves:\n",
        "    if 'x' in move:\n",
        "      if move.startswith('K'):\n",
        "        noOfCapturesByKing += 1\n",
        "      elif move.startswith('Q'):\n",
        "        noOfCapturesByQueen += 1\n",
        "      elif move.startswith('R'):\n",
        "        noOfCapturesByRook += 1\n",
        "      elif move.startswith('B'):\n",
        "        noOfCapturesByBishop += 1\n",
        "      elif move.startswith('N'):\n",
        "        noOfCapturesByKnight += 1\n",
        "      else:\n",
        "        noOfCapturesByPawn += 1\n",
        "  return noOfCapturesByKing,noOfCapturesByQueen,noOfCapturesByRook,noOfCapturesByBishop,noOfCapturesByKnight,noOfCapturesByPawn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWDxuaZApRx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate no of captures for all pieces for white early game\n",
        "(dropped_df['king_early_captures_white'],\n",
        "dropped_df['queen_early_captures_white'],\n",
        "dropped_df['rook_early_captures_white'],\n",
        "dropped_df['bishop_early_captures_white'],\n",
        "dropped_df['knight_early_captures_white'],\n",
        "dropped_df['pawn_early_captures_white']) = zip(*dropped_df['Early_stage_white_moves'].apply(capturesByEachPiece))\n",
        "\n",
        "#calculate no of captures for all pieces for white mid game\n",
        "(dropped_df['king_mid_captures_white'],\n",
        "dropped_df['queen_mid_captures_white'],\n",
        "dropped_df['rook_mid_captures_white'],\n",
        "dropped_df['bishop_mid_captures_white'],\n",
        "dropped_df['knight_mid_captures_white'],\n",
        "dropped_df['pawn_mid_captures_white']) = zip(*dropped_df['Mid_stage_white_moves'].apply(capturesByEachPiece))\n",
        "\n",
        "#calculate no of captures for all pieces for white end game\n",
        "(dropped_df['king_end_captures_white'],\n",
        "dropped_df['queen_end_captures_white'],\n",
        "dropped_df['rook_end_captures_white'],\n",
        "dropped_df['bishop_end_captures_white'],\n",
        "dropped_df['knight_end_captures_white'],\n",
        "dropped_df['pawn_end_captures_white']) = zip(*dropped_df['End_stage_white_moves'].apply(capturesByEachPiece))\n",
        "\n",
        "#calculate no of captures for all pieces for black early game\n",
        "(dropped_df['king_early_captures_black'],\n",
        "dropped_df['queen_early_captures_black'],\n",
        "dropped_df['rook_early_captures_black'],\n",
        "dropped_df['bishop_early_captures_black'],\n",
        "dropped_df['knight_early_captures_black'],\n",
        "dropped_df['pawn_early_captures_black']) = zip(*dropped_df['Early_stage_black_moves'].apply(capturesByEachPiece))\n",
        "\n",
        "#calculate no of captures for all pieces for black mid game\n",
        "(dropped_df['king_mid_captures_black'],\n",
        "dropped_df['queen_mid_captures_black'],\n",
        "dropped_df['rook_mid_captures_black'],\n",
        "dropped_df['bishop_mid_captures_black'],\n",
        "dropped_df['knight_mid_captures_black'],\n",
        "dropped_df['pawn_mid_captures_black']) = zip(*dropped_df['Mid_stage_black_moves'].apply(capturesByEachPiece))\n",
        "\n",
        "#calculate no of captures for all pieces for black mid game\n",
        "(dropped_df['king_end_captures_black'],\n",
        "dropped_df['queen_end_captures_black'],\n",
        "dropped_df['rook_end_captures_black'],\n",
        "dropped_df['bishop_end_captures_black'],\n",
        "dropped_df['knight_end_captures_black'],\n",
        "dropped_df['pawn_end_captures_black']) = zip(*dropped_df['End_stage_black_moves'].apply(capturesByEachPiece))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogmk-sNopV-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropped_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYUcMkMNpaGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop opening_ply and all moves column\n",
        "feature_extracted_df = dropped_df.drop(\n",
        "    ['opening_ply','moves','Early_stage_white_moves', 'Early_stage_black_moves',\n",
        "     'Mid_stage_white_moves', 'Mid_stage_black_moves','End_stage_white_moves',\n",
        "     'End_stage_black_moves',],\n",
        "     axis=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WseVIsrwpfZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of features: \",len(feature_extracted_df.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGF53m-TozkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop columns with only one unique value\n",
        "for col in feature_extracted_df.columns:\n",
        "    if len(feature_extracted_df[col].unique()) == 1:\n",
        "        print(col)\n",
        "        feature_extracted_df.drop(col,inplace=True,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOzXSJhhvB6Z",
        "colab_type": "text"
      },
      "source": [
        "#Converting Non-Numeric fields to numeric \n",
        "To find correlation, we need to convert all non-numeric fields to numeric. In our dataset, only target variable - \"winner\" is non-numeric. We convert it to numeric using \"astype\" function. This assigns a number to each unique category. In our case, a number to each of black, white and draw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN2Ob332o2d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert target to numerical data\n",
        "feature_extracted_df['winner'] = feature_extracted_df['winner'].astype('category')\n",
        "feature_extracted_df['winner'] = feature_extracted_df['winner'].cat.codes\n",
        "feature_extracted_df['winner']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLirvTTWo58X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform correlation between columns\n",
        "corr = feature_extracted_df.corr(method = \"pearson\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG1JwLJxsQj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
        "plt.figure().dpi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtSDMnnZo7qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#correlation of winner with other columns\n",
        "corr.winner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7_tLxtto95h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Selecting highly correlated features\n",
        "cor_target = abs(corr[\"winner\"])\n",
        "relevant_features = cor_target[cor_target>0.15]\n",
        "relevant_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rak2dCf6o_54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#select columns that have high correlation with output 'winner' column\n",
        "columns = [\"winner\",\n",
        "           \"black_rating\",\n",
        "           \"king_end_moves_white\",\n",
        "           \"queen_end_moves_white\",\n",
        "           \"king_end_moves_black\",\n",
        "           \"queen_end_moves_black\",\n",
        "           \"checks_end_white\",\n",
        "           \"checks_end_black\",\n",
        "           \"queen_end_captures_white\",\n",
        "           \"queen_end_captures_black\",\n",
        "           \"rook_end_captures_black\"\n",
        "]\n",
        "feature_engineered_df = feature_extracted_df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggbqUtLislfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display correlation between engineered features\n",
        "corr_features = feature_engineered_df.corr(method=\"pearson\")\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(corr_features, annot=True, cmap=plt.cm.Reds)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_oTlluxpBwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_engineered_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmkYnKZkwYSp",
        "colab_type": "text"
      },
      "source": [
        "#Train and Test Split\n",
        "The training set contains known output and the model learns on this data in order to be generalized to other data later on. We have the test dataset (or subset) in order to test our model‚Äôs prediction on this subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7guXT1dkq7El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split into train and test\n",
        "label = feature_engineered_df['winner']\n",
        "features = feature_engineered_df.drop('winner',axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2)\n",
        "print(\"Data before Split: \",features.shape)\n",
        "print(\"Training data: \",X_train.shape)\n",
        "print(\"Testing data: \",X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8wWGFsIKdbd",
        "colab_type": "text"
      },
      "source": [
        "##Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3R8Qjg6K_xW",
        "colab_type": "text"
      },
      "source": [
        "Conceptual Background\n",
        "---\n",
        "---\n",
        "**What is a Decision Tree?**\n",
        "* A graphical representation of possible solutions to a decision (based on certain conditions).\n",
        "* It starts with the root and branches off into a number of leaves.\n",
        "* A systematic process with a visual representation.\n",
        "\n",
        "\n",
        "---\n",
        "**Parts of a Decision Tree**\n",
        "* Each node represents a feature or attribute.\n",
        "* Each branch represents a decision or rule.\n",
        "* Each leaf represents an outcome.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Algorithms and Approaches to help build a Decision Tree?**\n",
        "* Classification and Regression Trees (CART algorithm)\n",
        "* Iterative Dichotomiser 3 (using entropy and information gain)\n",
        "* For this workshop, we will be using the Decision Tree Classifier provided by SciKit-Learn.\n",
        "\n",
        "---\n",
        "\n",
        "**Process**\n",
        "* Determine the root node. We pick the attribute that best classifies the training data.\n",
        "* Top-down process\n",
        "* Which attribute to choose? The one with the higest information gain.\n",
        "* Information gain is defined using a measure called \"entropy\".\n",
        "* ùêª(ùëã)=‚àí‚àëùëõùëñ=1ùëÉ(ùë•ùëñ)log2ùëÉ(ùë•ùëñ)\n",
        "\n",
        "---\n",
        "\n",
        "**Advantages of applying Decision Trees**\n",
        "* Easy usability and comprehension\n",
        "* Incredibly transparent and robust\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or-x99tpKiP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # imports the Decision Tree Classifier\n",
        "\n",
        "# We have already imported other libraries and loaded our data\n",
        "# We splitted our data into feature and target variables, as well as into training and test sets.\n",
        "\n",
        "# Now, we build the model.\n",
        "dtree = DecisionTreeClassifier() # creates Decision Tree classifier object\n",
        "\n",
        "# Trains Decision Tree classifier\n",
        "dtree.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wwp9XaULLpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Prediction of test dataset and evaluation of the model\n",
        "y_pred = dtree.predict(X_test) \n",
        "\n",
        "# Model Accuracy\n",
        "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxrHsxGMLi0q",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNmgZKwZxQ9c",
        "colab_type": "text"
      },
      "source": [
        "Conceptual Background\n",
        "---\n",
        "---\n",
        "**Assumptions**\n",
        "\n",
        "\n",
        "*   Our data can be split into 2 regions\n",
        "*   This split is linear, meaning no curves or folds, etc.\n",
        "*   Ex: In 2 dimensions, this split would be a line, and in 3 dimensions a plane\n",
        "*   Generally, we want a (n - 1) dimensional plane to split n-dimensional space into 2 classes\n",
        "*   We call this (n - 1) plane the linear discriminant, because 1) it's linear, 2) it discriminates between some class A and not A\n",
        "\n",
        "---\n",
        "**Goals**\n",
        "\n",
        "\n",
        "*   Given a input point **x** predict the probability that **x** belongs to the data class **y** - denoted *P<sub>y</sub>(x)*\n",
        "*   Ex: Given some characteristics about a person, whether they're above or below 130 pounds\n",
        "*   **x** would be the characteristics, and the possible classes would be above & below 130 pounds\n",
        "\n",
        "---\n",
        "\n",
        "**Process**: \n",
        "*This may be a little confusing for some, please ask me questions*\n",
        "* Let's simplify our model to 2 dimensions, so we're looking for a discriminator in 1 dimension\n",
        "* Because our plane is linear, it can be represented by *bias* + *C<sub>0</sub>x*\n",
        "* The issue is that this linear function also has range from (-$\\infty$,$\\infty$)\n",
        "* We need to map this to **(0, 1)** to represent a probabilitiy\n",
        "* We can do this by using the Sigmoid function, shown below\n",
        "* D: (-$\\infty$, $\\infty$) -> R: **(0, 1)** - this allows us to turn outputs from the linear discriminant into probability  *P<sub>y</sub>(x)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y-_nsopx7lM",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*Xu7B5y9gp0iL5ooBj7LtWw.png \"Sigmoid Function\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyu1WRnS0NpJ",
        "colab_type": "text"
      },
      "source": [
        "Importing necessary modules & Parameters\n",
        "---\n",
        "---\n",
        "**Pipeline**\n",
        "\n",
        "*   Describes a pipeline *(what a surprise)* of data transforms ending with an estimator of some kind\n",
        "*   In our example, StandardScaler is the only transform, and LogisticRegression is the estimator\n",
        "*   Useful for any kind of preprocessing required before actual training\n",
        "\n",
        "---\n",
        "**StandardScaler** \n",
        "*   Transforms all data x -> (x - u) / s\n",
        "*   \"Standardize features by removing the mean and scaling to unit variance\" - SkLearn Doc.\n",
        "*   Works by centering the sample data to a mean of 0 and squishing the data proportional to its standard deviation\n",
        "*   u (mu) is the mean of the sample data\n",
        "*   s is the sample standard deviation of the sample data\n",
        "\n",
        "---\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "1.   Let k be a value known as the regularization parameter\n",
        "2.   Higher values of k more heavily \"punish\" increases in parameter values\n",
        "3.   This is useful to prevent overfitting , as increasing values of k favor generalization rather than strong data fitting \n",
        "4.   Can be thought of as painting with wide strokes rather than with a thin paint brush\n",
        "5.   C = 1/k, so C is just the inverse of k. Hence higher values of C punish parameter weights less heavily, favoring data fitting\n",
        "\n",
        "---\n",
        "\n",
        "**Fitting** \n",
        "\n",
        "*   Modern libraries allow us to abstract away all the computation.\n",
        "*    **lr_pipeline.fit (** *X_train*, *y_train* **) ** starts the model's process of finding a pseudo-optimal parameter set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20FkkAha0QB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Scaling Pipeline + Logistic Regression estimator\n",
        "lr_pipeline = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(C=0.00001))])\n",
        "\n",
        "\n",
        "# Model training below\n",
        "lr_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZM1PYKr299u",
        "colab_type": "text"
      },
      "source": [
        "Model Accuracy Testing\n",
        "---\n",
        "\n",
        "**Predict**\n",
        "\n",
        "\n",
        "*   Used to test the performance of trained models on data\n",
        "*   **lr_pipeline_predict** returns a vector containing the model predictions for each entry in ***X_test***\n",
        "*  **accuracy_score** is used to compare the predicted values ***y_pred*** against the ground truth ***y_test***\n",
        "* **classification_report** is used to summarize the data the model prediction and reality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QEEzXva3Fym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = lr_pipeline.predict(X_test) # getting the list of predictions with input X_test (data model hasn't seen)\n",
        "print('Accuracy: ', accuracy_score(y_test, y_pred)) # getting accuracy of the predicted output vs. ground truth\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}